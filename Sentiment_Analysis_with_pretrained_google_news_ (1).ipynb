{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis with pretrained google news .ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvo-nKWEOxDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndC95FWdO5uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#data dependencies \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46g3vV5cO67w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Aunthenticate\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGM6xEFmO9vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Link : https://drive.google.com/open?id=1NWrf1adDUBbA5MM3q-gqr0bZu1SrtILX\n",
        "# Testing Link : https://drive.google.com/open?id=1RHIIZ34VGN5BEha3_OMSq4CmVVxvY-Fm\n",
        "\n",
        "train_downloaded = drive.CreateFile({'id':'1NWrf1adDUBbA5MM3q-gqr0bZu1SrtILX'})\n",
        "train_downloaded.GetContentFile('clean_tweet_training.csv')\n",
        "test_downloaded = drive.CreateFile({'id':'1RHIIZ34VGN5BEha3_OMSq4CmVVxvY-Fm'})\n",
        "test_downloaded.GetContentFile('clean_tweet_testing.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWmIkvlkOxDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('clean_tweet_training.csv')\n",
        "test_df = pd.read_csv('clean_tweet_testing.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuUTOupnPkC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pretrained Link : https://drive.google.com/a/mail.ugm.ac.id/uc?export=download&confirm=19S_&id=1-UJRiTvSnmyrK61CDiCFq5ql1q_mK5D-\n",
        "\n",
        "pretrained_download = drive.CreateFile({'id':'1-UJRiTvSnmyrK61CDiCFq5ql1q_mK5D-'})\n",
        "pretrained_download.GetContentFile('GoogleNews.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoIz07Q2OxD-",
        "colab_type": "code",
        "outputId": "c7b4c7a7-ba27-4801-ec13-3fa77a90b1b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>awww bummer shoulda got david carr third day</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>upset update facebook texting might cry result...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>dived many times ball managed save rest go bounds</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>whole body feels itchy like fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>behaving mad see</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                               text  target\n",
              "0      0       awww bummer shoulda got david carr third day       0\n",
              "1      1  upset update facebook texting might cry result...       0\n",
              "2      2  dived many times ball managed save rest go bounds       0\n",
              "3      3                   whole body feels itchy like fire       0\n",
              "4      4                                   behaving mad see       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rls8Ue1pOxEU",
        "colab_type": "code",
        "outputId": "93762e7d-488f-4d36-e163-9e3d588a0ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>loooooooovvvvvveee kindle dx cool fantastic right</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>reading kindle love lee childs good read</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ok first assesment kindle fucking rocks</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>love kindle mine months never looked back new ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>fair enough kindle think perfect</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                               text  target\n",
              "0      0  loooooooovvvvvveee kindle dx cool fantastic right     1.0\n",
              "1      1           reading kindle love lee childs good read     1.0\n",
              "2      2            ok first assesment kindle fucking rocks     1.0\n",
              "3      3  love kindle mine months never looked back new ...     1.0\n",
              "4      4                   fair enough kindle think perfect     1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTQ5uHM3OxEh",
        "colab_type": "code",
        "outputId": "2ea0c6f8-795b-4c62-a8f6-486f1836b054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Processing text dataset')\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from collections import Counter\n",
        "from string import punctuation, ascii_lowercase\n",
        "import regex as re\n",
        "from tqdm import tqdm\n",
        "\n",
        "# replace urls\n",
        "re_url = re.compile(r\"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\\n",
        "                    .([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\",\n",
        "re.MULTILINE|re.UNICODE)\n",
        "\n",
        "# replace ips\n",
        "re_ip = re.compile(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\")\n",
        "\n",
        "# setup tokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "vocab = Counter()\n",
        "\n",
        "def text_to_wordlist(text, lower=False):\n",
        "    # replace URLs\n",
        "    text = re_url.sub(\"URL\", text)\n",
        "    # replace IPs\n",
        "    text = re_ip.sub(\"IPADDRESS\", text)\n",
        "    # Tokenize\n",
        "    text = tokenizer.tokenize(text)\n",
        "    # optional: lower case\n",
        "    if lower:\n",
        "        text = [t.lower() for t in text]\n",
        "        # Return a list of words\n",
        "        vocab.update(text)\n",
        "    return text\n",
        "\n",
        "def process_comments(list_sentences, lower=False):\n",
        "    comments = []\n",
        "    for text in tqdm(list_sentences):\n",
        "        txt = text_to_wordlist(text, lower=lower)\n",
        "        comments.append(txt)\n",
        "    return comments\n",
        "\n",
        "list_sentences_train = list(train_df[\"text\"].fillna(\"NAN_WORD\").values)\n",
        "list_sentences_test = list(test_df[\"text\"].fillna(\"NAN_WORD\").values)\n",
        "comments = process_comments(list_sentences_train + list_sentences_test, lower=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing text dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1600498/1600498 [00:19<00:00, 82147.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI4Tz5_hOxEv",
        "colab_type": "code",
        "outputId": "becc6d1c-9726-4668-ec7c-60375deeef7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The vocabulary contains {} unique tokens\".format(len(vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The vocabulary contains 273627 unique tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGmZn91hOxE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh2lZGPXOxFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load pre-trained Word2Vec model.\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(\"GoogleNews.bin\", binary=True)  # C bin format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HMrkdGHOxFN",
        "colab_type": "code",
        "outputId": "af965dc6-028a-4d40-f645-d2e754838d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "word_vectors = wv_from_bin.wv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWPOAMspOxFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wv_from_bin.wv.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EltildufOxFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = len(word_vectors.vocab)\n",
        "MAX_SEQUENCE_LENGTH = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj6ujodw6JsR",
        "colab_type": "code",
        "outputId": "5023a571-1390-41d9-da02-ae91107b649e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "word_index = {t[0]: i+1 for i,t in enumerate(vocab.most_common(MAX_NB_WORDS))}\n",
        "sequences = [[word_index.get(t, 0) for t in comment]\n",
        "             for comment in comments[:len(list_sentences_train)]]\n",
        "test_sequences = [[word_index.get(t, 0)  for t in comment] \n",
        "                  for comment in comments[len(list_sentences_train):]]\n",
        "\n",
        "# pad\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, \n",
        "                     padding=\"pre\", truncating=\"post\")\n",
        "list_classes = [\"target\"]\n",
        "y = train_df[list_classes].values\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', y.shape)\n",
        "\n",
        "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\",\n",
        "                          truncating=\"post\")\n",
        "print('Shape of test_data tensor:', test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1600000, 200)\n",
            "Shape of label tensor: (1600000, 1)\n",
            "Shape of test_data tensor: (498, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEdP6rh66WXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WV_DIM = 100\n",
        "nb_words = min(MAX_NB_WORDS, len(word_vectors.vocab))\n",
        "# we initialize the matrix with random numbers\n",
        "wv_matrix = (np.random.rand(nb_words, WV_DIM) - 0.5) / 5.0\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NB_WORDS:\n",
        "        continue\n",
        "    try:\n",
        "        embedding_vector = word_vectors[word]\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        wv_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        pass      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU-3hshv6ars",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Input, Conv1D, MaxPooling1D, BatchNormalization, LSTM, Dense, Dropout, Embedding, SpatialDropout1D, CuDNNLSTM, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DafYof9h6fbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wv_layer = Embedding(nb_words,\n",
        "                     WV_DIM,\n",
        "                     mask_zero=False,\n",
        "                     weights=[wv_matrix],\n",
        "                     input_length=MAX_SEQUENCE_LENGTH,\n",
        "                     trainable=False)\n",
        "\n",
        "# Inputs\n",
        "comment_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = wv_layer(comment_input)\n",
        "\n",
        "# Embedded\n",
        "embedded_sequences = SpatialDropout1D(0.2)(embedded_sequences)\n",
        "\n",
        "#Convolutional1D\n",
        "x = Conv1D(filters=3, kernel_size=64, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(embedded_sequences)\n",
        "\n",
        "#MaxPoolingLayer1D\n",
        "x = MaxPooling1D(pool_size=2, strides=None, padding='valid', data_format='channels_last')(x)\n",
        "\n",
        "#DropoutLayers\n",
        "x = Dropout(rate=0, noise_shape=None, seed=None)(x)\n",
        "\n",
        "#BatchNormalization\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "#LSTM\n",
        "x = LSTM(units=128, activation='relu', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initiali0zer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)(x)\n",
        "\n",
        "preds = Dense(1, activation='relu')(x)\n",
        "\n",
        "# build the model\n",
        "model = Model(inputs=[comment_input], outputs=preds)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=0.001, clipnorm=.25, beta_1=0.7, beta_2=0.99),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlrLnGcQ6j9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit([data], y, validation_split=0.1, epochs=8, batch_size=256, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyqYxzgk6moB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEeFXXW16pCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = pd.DataFrame(hist.history)\n",
        "plt.figure(figsize=(12,12));\n",
        "plt.plot(history[\"loss\"]);\n",
        "plt.plot(history[\"val_loss\"]);\n",
        "plt.title(\"Loss with pretrained word vectors\");\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9ofTt066uYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.iloc[0:6,3]\n",
        "loss = history.iloc[0:6,2]\n",
        "history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzEVGjJI6xTw",
        "colab_type": "code",
        "outputId": "a7243c6c-dab5-484f-c9ac-1cf6bc80b124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "plt.plot(acc, color='g');\n",
        "# plt.plot(loss, color='blue');\n",
        "plt.title(\"Accuray Function\");\n",
        "plt.show();\n",
        "# plt.plot(acc, color='g');\n",
        "plt.plot(loss, color='blue');\n",
        "plt.title(\"Loss Function\");\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a5c9c56d58fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# plt.plot(loss, color='blue');\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuray Function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plt.plot(acc, color='g');\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ]
}